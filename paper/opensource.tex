


\begin{table}
{\scriptsize
\begin{center}
\begin{tabular}{|c||c|c|c|c|c||c|c|c|c|c|}
\hline
\hline
& \multicolumn{3}{|c|}{Program Source} & \multicolumn{1}{|c|}{Test Suite} \\
\hline
Subject & \#Classes. & \#Methods & SLOC & \#Test cases \\
\hline
\hline
{\tt Apache Commons} & & & & \\
{\tt Validator} & 64 & 578 & 6,033 & 434 \\
\hline
{\tt JExel 1.0.0} & & & & \\
{\tt beta 13} & 43 & 133 & 1,522	 & 344  \\
\hline
{\tt JAxen} & 167 & 1,078 & 12,462 & 2,138\\
\hline
{\tt JParser} & 115 & 178 & 3,046 & 647 \\
\hline
{\tt Apache Commons} & & & & \\
{\tt CLI} & 23 & 208 & 2,667 & 364 \\ 
\hline
\hline
\end{tabular}
\end{center}
}
\caption{Open Source Subject Programs}
\label{tab:opensourcesubs}
\end{table}



Next we applied reduction based localization to five open source Java
programs (shown in Table \ref{tab:opensourcesubs}), generating mutants
for each of the projects to simulate bugs as in some recent
localization papers \cite{mutant,PureTest}.





 
Our strategy was to create mutants using the approach of Xuan and
Monperrus \cite{PureTest}, using 6 mutant operators.  From each set of
mutants generated, we selected 5 or 6 mutants at random that met the
following criteria: (1) the mutant was killed by at least one test
case and (2) the mutant generated no errors in JUnit test cases.  A
JUnit failure is caused by an unsatisfied assertion, but an error is
caused by another kind of test failure, which may include some test
setup or oracle problems.  Using assertion failures only assured that
we retained the intent of the original tests.

Taking all the open source projects and mutants together, we note that
reduction improved fault ranking in 51 cases, left it unchanged in 55
cases, and made it worse in only 2 cases.  The average improvement was
17.62 ranking positions; the average negative effect size was 2
ranking positions.  The best improvement was 100 rank positions.  The
average fault ranking without reduction was 37.64, and with reduction
this improved to 29.36.
